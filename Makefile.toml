[tasks.fmt]
description = "Format source code"
workspace = false
install_script = ['''
#!/usr/bin/env bash
rustup which rustfmt --toolchain nightly
if [ $? -ne 0 ]; then
  rustup install nightly
fi
''']
script = '''
#!/usr/bin/env bash
cargo +nightly fmt
'''

[tasks.sort-dependencies]
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! toml_edit = "0.22.0"
//! ```
use std::fs;
use std::path::Path;
use toml_edit::{Document, Item, Table, InlineTable};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cargo_toml_paths = [
        "Cargo.toml",
        "modules/utils-core/Cargo.toml",
        "modules/utils-std/Cargo.toml",
        "modules/message-derive-core/Cargo.toml",
        "modules/message-derive-std/Cargo.toml",
        "modules/actor-core/Cargo.toml",
        "modules/actor-std/Cargo.toml",
        "modules/remote-core/Cargo.toml",
        "modules/remote-std/Cargo.toml",
        "modules/cluster-core/Cargo.toml",
        "modules/cluster-std/Cargo.toml",
    ];

    for path in cargo_toml_paths.iter() {
        let path = Path::new(path);
        if path.exists() {
            backup_cargo_toml(path)?;
            sort_dependencies(path)?;
        } else {
            println!("Warning: {} not found", path.display());
        }
    }

    Ok(())
}

// Create a backup of Cargo.toml -> Cargo.toml.bak
fn backup_cargo_toml(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let backup_path = file_path.with_extension("toml.bak");
    fs::copy(file_path, &backup_path)?;
    println!("Backup created: {}", backup_path.display());
    Ok(())
}

fn sort_table(table: &mut Table) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_inline_table(table: &mut InlineTable) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_dependencies(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let content = fs::read_to_string(file_path)?;
    let mut doc = content.parse::<Document>()?;

    // Sort workspace dependencies
    if let Some(workspace) = doc.get_mut("workspace") {
        if let Some(deps) = workspace.get_mut("dependencies") {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted workspace.dependencies in {}", file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted workspace.dependencies in {}", file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    // Sort other dependency sections
    let sections = ["dependencies", "dev-dependencies", "build-dependencies"];

    for section in sections.iter() {
        if let Some(deps) = doc.get_mut(section) {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted {} in {}", section, file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted {} in {}", section, file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    fs::write(file_path, doc.to_string())?;
    println!("Updated {} successfully", file_path.display());

    Ok(())
}
'''

[tasks.check-source-policy]
description = "Enforce source policy: ban mod.rs and one top-level type/trait per file (workspace-aware, ignores tests.rs/lib.rs/main.rs)"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! regex = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use regex::Regex;
use std::{collections::{BTreeMap, HashSet}, env, fs, path::{Path, PathBuf}};
use toml::Value;
use walkdir::WalkDir;

#[derive(Clone)]
struct TypeInfo {
    kind: &'static str,
    name: String,
}

struct TypeCollection {
    items: Vec<TypeInfo>,
    has_alias_or_union: bool,
}

struct MultiTypeViolation {
    path: PathBuf,
    items: Vec<TypeInfo>,
    has_alias_or_union: bool,
}

const RESERVED_FILE_BASENAMES: &[&str] = &["core", "common"];

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("ONE_TYPE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_comment(src: &str) -> bool {
    src.lines().take(80).any(|l| l.contains("allow:multi-types"))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn collect_top_level_types(src: &str) -> Result<TypeCollection> {
    let file = syn::parse_file(src)?;
    use syn::Item::*;
    let mut items: Vec<TypeInfo> = Vec::new();
    let mut has_alias_or_union = false;
    let mut seen: HashSet<String> = HashSet::new();
    for item in file.items {
        match item {
            Struct(data) => {
                let name = data.ident.to_string();
                let key = format!("struct:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "struct", name });
                }
            }
            Enum(data) => {
                let name = data.ident.to_string();
                let key = format!("enum:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "enum", name });
                }
            }
            Trait(data) => {
                let name = data.ident.to_string();
                let key = format!("trait:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "trait", name });
                }
            }
            Type(_) | Union(_) => has_alias_or_union = true,
            _ => {}
        }
    }
    Ok(TypeCollection { items, has_alias_or_union })
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let re_modrs = Regex::new(r"(^|/|\\)mod\\.rs$").unwrap();
    let mut errors: Vec<(String, String)> = Vec::new();
    let mut multi_type_violations: Vec<MultiTypeViolation> = Vec::new();

    for dir in &dirs {
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            if re_modrs.is_match(&path.to_string_lossy()) {
                let module = path.parent().unwrap_or(Path::new(".")).display().to_string();
                errors.push((module, format!("mod.rs is not allowed: {}", path.display())));
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;
            if has_allow_comment(&src) {
                continue;
            }

            match collect_top_level_types(&src) {
                Ok(collection) => {
                    if collection.items.len() > 1 {
                        multi_type_violations.push(MultiTypeViolation {
                            path: path.to_path_buf(),
                            items: collection.items,
                            has_alias_or_union: collection.has_alias_or_union,
                        });
                    }
                }
                Err(e) => {
                    let module = path.parent().unwrap_or(Path::new(".")).display().to_string();
                    errors.push((module, format!("Parse error in {}: {e}", path.display())));
                }
            }
        }
    }

    if errors.is_empty() && multi_type_violations.is_empty() {
        println!("[OK] source policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        const MAX_MODULES: usize = 20;
        const MAX_WARNINGS_PER_MODULE: usize = 5;

        let mut grouped: BTreeMap<String, Vec<String>> = BTreeMap::new();

        for (module, message) in errors {
            grouped.entry(module).or_default().push(message);
        }

        for violation in multi_type_violations {
            let module = violation
                .path
                .parent()
                .unwrap_or(Path::new("."))
                .display()
                .to_string();

            let entry = grouped.entry(module).or_default();
            entry.push(format!(
                "{} has {} top-level type/trait definitions",
                violation.path.display(),
                violation.items.len()
            ));

            let max_items = 3usize.min(violation.items.len());
            for item in violation.items.iter().take(max_items) {
                let suggestion = format_suggestion(&violation.path, item);
                entry.push(format!("    - {} {} -> {}", item.kind, item.name, suggestion));
            }
            if violation.items.len() > max_items {
                entry.push(format!("    ... {} additional type(s) omitted", violation.items.len() - max_items));
            }
            let dir = violation.path.parent().unwrap_or(Path::new("."));
            let core_path = dir.join("core.rs");
            if violation.path.file_name().and_then(|s| s.to_str()) == Some("core.rs") {
                entry.push(format!(
                    "    > After extraction: keep {} for module wiring only (`pub mod ...; pub use ...`).",
                    violation.path.display()
                ));
            } else if core_path.exists() {
                entry.push(format!(
                    "    > After extraction: migrate module wiring from {} into existing {} (use `pub mod ...; pub use ...`).",
                    violation.path.display(),
                    core_path.display()
                ));
            } else {
                entry.push(format!(
                    "    > After extraction: rename {} to {} and keep only module wiring (`pub mod ...; pub use ...`).",
                    violation.path.display(),
                    core_path.display()
                ));
            }
            if violation.has_alias_or_union {
                let common_path = dir.join("common.rs");
                entry.push(format!(
                    "    > Remaining type aliases or unions? move them into {}.",
                    common_path.display()
                ));
            }
        }

        eprintln!("source policy violations:");
        for (idx, (module, messages)) in grouped.iter().enumerate() {
            if idx >= MAX_MODULES {
                let remaining = grouped.len().saturating_sub(MAX_MODULES);
                if remaining > 0 {
                    eprintln!("  ... {} more module(s) containing violations (output truncated)", remaining);
                }
                break;
            }

            eprintln!("  module: {} ({} violation(s))", module, messages.len());
            for (i, message) in messages.iter().enumerate() {
                if i >= MAX_WARNINGS_PER_MODULE {
                    let remaining = messages.len().saturating_sub(MAX_WARNINGS_PER_MODULE);
                    if remaining > 0 {
                        eprintln!("    ... {} additional violation(s) in this module", remaining);
                    }
                    break;
                }
                eprintln!("    - {message}");
            }
        }
        Err(anyhow!("violations found"))
    }
}

fn format_suggestion(path: &Path, item: &TypeInfo) -> String {
    let dir = path.parent().unwrap_or(Path::new("."));
    let mut snake = to_snake_case(&item.name);
    if snake.is_empty() {
        snake = String::from("generated_type");
    }
    if RESERVED_FILE_BASENAMES.contains(&snake.as_str()) {
        snake.push_str("_type");
    }
    let file_name = format!("{}.rs", snake);
    let target = dir.join(&file_name);
    if target == path {
        format!("create {}", target.display())
    } else if target.exists() {
        format!("merge into existing {}", target.display())
    } else {
        format!("create {}", target.display())
    }
}

fn to_snake_case(name: &str) -> String {
    let mut result = String::new();
    let mut chars = name.chars().peekable();
    let mut prev_is_upper = false;
    let mut prev_is_underscore = false;
    while let Some(ch) = chars.next() {
        if ch.is_uppercase() {
            let next_is_lower = chars.peek().map(|c| c.is_lowercase()).unwrap_or(false);
            if !result.is_empty() && !prev_is_underscore && (!prev_is_upper || next_is_lower) {
                result.push('_');
            }
            for lower in ch.to_lowercase() {
                result.push(lower);
            }
            prev_is_upper = true;
            prev_is_underscore = false;
        } else if ch == '-' || ch == ' ' {
            if !result.ends_with('_') {
                result.push('_');
            }
            prev_is_upper = false;
            prev_is_underscore = true;
        } else {
            result.push(ch.to_ascii_lowercase());
            prev_is_upper = false;
            prev_is_underscore = ch == '_';
        }
    }
    result.trim_matches('_').to_string()
}
'''

[tasks.check-impl-co-location]
description = "Ensure struct definitions and inherent impl blocks live in the same file"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use std::collections::{HashMap, HashSet};
use std::{env, fs, path::{Path, PathBuf}};
use toml::Value;
use walkdir::WalkDir;

#[derive(Clone)]
struct FileEntry {
    path: PathBuf,
    allow_scatter: bool,
}

#[derive(Hash, Eq, PartialEq, Clone)]
struct TypeKey {
    crate_root: PathBuf,
    name: String,
}

#[derive(Default)]
struct TypeData {
    defs: Vec<FileEntry>,
    impls: Vec<FileEntry>,
}

const MULTI_DEF_ALLOWLIST: &[&str] = &["Inner"];

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("ONE_TYPE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_tag(src: &str, tag: &str) -> bool {
    src.lines().take(80).any(|l| l.contains(tag))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn dedup_entries(mut entries: Vec<FileEntry>) -> Vec<FileEntry> {
    entries.sort_by(|a, b| a.path.cmp(&b.path));
    entries.dedup_by(|a, b| a.path == b.path);
    entries
}

fn find_crate_root(dir: &Path) -> Option<PathBuf> {
    let mut current = dir;
    loop {
        if is_file_exists(&current.join("Cargo.toml")) {
            return Some(current.to_path_buf());
        }
        match current.parent() {
            Some(parent) => current = parent,
            None => return None,
        }
    }
}

fn collect_items(
    items: &[syn::Item],
    map: &mut HashMap<TypeKey, TypeData>,
    file_entry: &FileEntry,
    crate_root: &Path,
) {
    use syn::Item;
    for item in items {
        match item {
            Item::Struct(item_struct) => {
                let key = TypeKey {
                    crate_root: crate_root.to_path_buf(),
                    name: item_struct.ident.to_string(),
                };
                map.entry(key).or_default().defs.push(file_entry.clone());
            }
            Item::Impl(item_impl) => {
                if item_impl.trait_.is_none() {
                    if let Some(name) = extract_type_ident(&item_impl.self_ty) {
                        let key = TypeKey {
                            crate_root: crate_root.to_path_buf(),
                            name,
                        };
                        map.entry(key).or_default().impls.push(file_entry.clone());
                    }
                }
            }
            Item::Mod(item_mod) => {
                if let Some((_, nested)) = &item_mod.content {
                    collect_items(nested, map, file_entry, crate_root);
                }
            }
            _ => {}
        }
    }
}

fn extract_type_ident(ty: &syn::Type) -> Option<String> {
    match ty {
        syn::Type::Path(type_path) => {
            if type_path.qself.is_some() {
                return None;
            }
            type_path.path.segments.last().map(|seg| seg.ident.to_string())
        }
        _ => None,
    }
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let mut types: HashMap<TypeKey, TypeData> = HashMap::new();

    for dir in &dirs {
        let crate_root = find_crate_root(dir).unwrap_or_else(|| dir.clone());
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;
            let allow_scatter = has_allow_tag(&src, "allow:impl-scatter");

            let parsed = syn::parse_file(&src)
                .with_context(|| format!("failed to parse {}", path.display()))?;

            let file_entry = FileEntry {
                path: path.to_path_buf(),
                allow_scatter,
            };

            collect_items(&parsed.items, &mut types, &file_entry, &crate_root);
        }
    }

    let mut errors: Vec<String> = Vec::new();

    for (key, data) in types {
        let defs = dedup_entries(data.defs);
        let impls = dedup_entries(data.impls);

        if defs.is_empty() {
            continue; // likely external type
        }

        if defs.len() > 1 {
            if MULTI_DEF_ALLOWLIST.iter().any(|&name| name == key.name) {
                continue;
            }
            let locations = defs
                .iter()
                .map(|entry| entry.path.display().to_string())
                .collect::<Vec<_>>()
                .join(", ");
            errors.push(format!(
                "構造体 `{}` が複数のファイルで定義されています: {}",
                key.name,
                locations
            ));
            continue;
        }

        let def = &defs[0];
        if def.allow_scatter {
            continue;
        }

        for impl_entry in impls {
            if impl_entry.allow_scatter {
                continue;
            }

            if impl_entry.path != def.path {
                errors.push(format!(
                    "構造体 `{}` の定義({})とinherent impl({})が別ファイルにあります",
                    key.name,
                    def.path.display(),
                    impl_entry.path.display()
                ));
            }
        }
    }

    if errors.is_empty() {
        println!("[OK] impl co-location policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        eprintln!("impl co-location violations:");
        for err in &errors {
            eprintln!("  - {err}");
        }
        Err(anyhow!("violations found"))
    }
}
'''

[tasks.check-package-exposure]
description = "Enforce Java-style package re-exports (no deep crate:: paths or wildcard exports)"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use std::collections::{HashMap, HashSet};
use std::{env, fs, path::{Path, PathBuf}};
use syn::{Item, UseTree, Visibility};
use toml::Value;
use walkdir::WalkDir;

const ALLOW_TAGS: [&str; 2] = ["allow:module-expose", "allow:package-reexport"];

#[derive(Clone)]
struct UseEntry {
    path: Vec<String>,
    alias: Option<String>,
    is_glob: bool,
}

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("PACKAGE_EXPOSE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_tag(src: &str) -> bool {
    src.lines()
        .take(80)
        .any(|line| ALLOW_TAGS.iter().any(|tag| line.contains(tag)))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn is_prelude_path(path: &Path) -> bool {
    path.components().any(|c| c.as_os_str() == "prelude")
        || path.file_stem().and_then(|s| s.to_str()) == Some("prelude")
}

fn gather_use_tree(tree: &UseTree, prefix: &mut Vec<String>, entries: &mut Vec<UseEntry>) {
    match tree {
        UseTree::Path(path) => {
            prefix.push(path.ident.to_string());
            gather_use_tree(&path.tree, prefix, entries);
            prefix.pop();
        }
        UseTree::Name(name) => {
            let mut path = prefix.clone();
            path.push(name.ident.to_string());
            entries.push(UseEntry { path, alias: None, is_glob: false });
        }
        UseTree::Rename(rename) => {
            let mut path = prefix.clone();
            path.push(rename.ident.to_string());
            entries.push(UseEntry {
                path,
                alias: Some(rename.rename.to_string()),
                is_glob: false,
            });
        }
        UseTree::Glob(_) => {
            entries.push(UseEntry {
                path: prefix.clone(),
                alias: None,
                is_glob: true,
            });
        }
        UseTree::Group(group) => {
            for item in &group.items {
                gather_use_tree(item, prefix, entries);
            }
        }
    }
}

fn format_path(parts: &[String]) -> String {
    if parts.is_empty() {
        "(self)".to_string()
    } else {
        parts.join("::")
    }
}

fn format_use_entry(entry: &UseEntry) -> String {
    let mut s = format_path(&entry.path);
    if let Some(alias) = &entry.alias {
        s.push_str(" as ");
        s.push_str(alias);
    }
    s
}

fn is_public(vis: &Visibility) -> bool {
    matches!(vis, Visibility::Public(_) | Visibility::Restricted(_))
}

fn collect_base_path(entry: &UseEntry) -> Option<Vec<String>> {
    if entry.path.is_empty() {
        return None;
    }
    if entry.is_glob {
        Some(entry.path.clone())
    } else if entry.path.len() >= 1 {
        let mut base = entry.path.clone();
        base.pop();
        Some(base)
    } else {
        None
    }
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let mut violations: HashSet<String> = HashSet::new();

    for dir in &dirs {
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;

            if has_allow_tag(&src) || is_prelude_path(path) {
                continue;
            }

            let syntax = syn::parse_file(&src)
                .with_context(|| format!("failed to parse {}", path.display()))?;

            for item in &syntax.items {
                if let Item::Use(item_use) = item {
                    if !is_public(&item_use.vis) {
                        continue;
                    }

                    let mut entries = Vec::new();
                    gather_use_tree(&item_use.tree, &mut Vec::new(), &mut entries);
                    if entries.is_empty() {
                        continue;
                    }

                    // Detect glob re-exports and deep crate paths
                    for entry in &entries {
                        if entry.is_glob {
                            if entry.path.first().map(|s| s == "crate").unwrap_or(false) {
                                let glob_str = format!("{}::*", format_path(&entry.path));
                                violations.insert(format!(
                                    "{}: wildcard re-export `{}` exposes entire module; prefer explicit package api modules",
                                    path.display(), glob_str
                                ));
                            }
                            continue;
                        }

                        if entry.path.len() > 1 && entry.path.first().map(|s| s == "crate").unwrap_or(false) {
                            let usage = format_use_entry(entry);
                            violations.insert(format!(
                                "{}: re-export `{}` publishes internal module structure; re-export it from the package-level api module instead",
                                path.display(), usage
                            ));
                        }
                    }

                    // Detect multiple deep re-exports from the same crate path
                    let mut base_map: HashMap<Vec<String>, Vec<&UseEntry>> = HashMap::new();
                    for entry in &entries {
                        if entry.is_glob {
                            continue;
                        }
                        if let Some(base) = collect_base_path(entry) {
                            if base.first().map(|s| s == "crate").unwrap_or(false) {
                                base_map.entry(base).or_default().push(entry);
                            }
                        }
                    }

                    for (base, items) in base_map {
                        if items.len() > 1 {
                            let base_str = format_path(&base);
                            let names = items
                                .iter()
                                .map(|entry| entry.alias.as_deref().unwrap_or_else(|| entry.path.last().unwrap()).to_string())
                                .collect::<Vec<_>>()
                                .join(", ");
                            violations.insert(format!(
                                "{}: multiple re-exports from `{}` ({}) detected; create a dedicated package api module instead",
                                path.display(), base_str, names
                            ));
                        }
                    }
                }
            }
        }
    }

    if violations.is_empty() {
        println!("[OK] package exposure policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        let mut sorted: Vec<_> = violations.into_iter().collect();
        sorted.sort();
        eprintln!("package exposure violations:");
        for violation in sorted {
            eprintln!("  - {violation}");
        }
        Err(anyhow!("violations found"))
    }
}
'''

[tasks.check-reexport-hierarchy]
description = "Verify that modules only re-export their descendants"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use std::collections::{BTreeMap, HashSet};
use std::{env, fs, path::{Path, PathBuf}};
use syn::{Item, UseTree, Visibility};
use toml::Value;
use walkdir::WalkDir;

const ALLOW_TAG: &str = "allow:cross-reexport";

#[derive(Clone)]
struct UseEntry {
    path: Vec<String>,
    alias: Option<String>,
    is_glob: bool,
}

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("REEXPORT_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_tag(src: &str) -> bool {
    src.lines().take(80).any(|line| line.contains(ALLOW_TAG))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("build.rs") | Some("tests.rs")
    )
}

fn is_prelude_path(path: &Path) -> bool {
    path.components().any(|c| c.as_os_str() == "prelude")
        || path.file_stem().and_then(|s| s.to_str()) == Some("prelude")
}

fn gather_use_tree(tree: &UseTree, prefix: &mut Vec<String>, entries: &mut Vec<UseEntry>) {
    match tree {
        UseTree::Path(path) => {
            prefix.push(path.ident.to_string());
            gather_use_tree(&path.tree, prefix, entries);
            prefix.pop();
        }
        UseTree::Name(name) => {
            let mut path = prefix.clone();
            path.push(name.ident.to_string());
            entries.push(UseEntry { path, alias: None, is_glob: false });
        }
        UseTree::Rename(rename) => {
            let mut path = prefix.clone();
            path.push(rename.ident.to_string());
            entries.push(UseEntry {
                path,
                alias: Some(rename.rename.to_string()),
                is_glob: false,
            });
        }
        UseTree::Glob(_) => {
            entries.push(UseEntry {
                path: prefix.clone(),
                alias: None,
                is_glob: true,
            });
        }
        UseTree::Group(group) => {
            for item in &group.items {
                gather_use_tree(item, prefix, entries);
            }
        }
    }
}

fn module_path_from(src_root: &Path, file: &Path) -> Option<Vec<String>> {
    let rel = file.strip_prefix(src_root).ok()?;
    let mut parts: Vec<String> = rel
        .components()
        .map(|c| c.as_os_str().to_string_lossy().to_string())
        .collect();
    if parts.is_empty() {
        return Some(vec![]);
    }

    let file_name = parts.pop().unwrap();
    let mut module_path = parts;

    match file_name.as_str() {
        "lib.rs" | "main.rs" => {}
        "mod.rs" => return None,
        _ => {
            let stem = Path::new(&file_name)
                .file_stem()
                .and_then(|s| s.to_str())
                .unwrap_or(&file_name);
            module_path.push(stem.to_string());
        }
    }

    Some(module_path)
}

fn resolve_absolute_path(module_path: &[String], segments: &[String]) -> Option<Vec<String>> {
    if segments.is_empty() {
        return None;
    }

    match segments[0].as_str() {
        "crate" => {
            if segments.len() == 1 {
                Some(vec![])
            } else {
                Some(segments[1..].to_vec())
            }
        }
        "self" => {
            let mut base = module_path.to_vec();
            base.extend_from_slice(&segments[1..]);
            Some(base)
        }
        "super" => {
            let mut base = module_path.to_vec();
            let mut idx = 0usize;
            while idx < segments.len() && segments[idx] == "super" {
                if base.is_empty() {
                    return None;
                }
                base.pop();
                idx += 1;
            }
            base.extend_from_slice(&segments[idx..]);
            Some(base)
        }
        _ => None,
    }
}

fn module_path_to_string(path: &[String]) -> String {
    if path.is_empty() {
        "crate".to_string()
    } else {
        path.join("::")
    }
}

fn format_use_entry(entry: &UseEntry) -> String {
    let mut s = if entry.path.is_empty() {
        String::from("(self)")
    } else {
        entry.path.join("::")
    };
    if let Some(alias) = &entry.alias {
        s.push_str(" as ");
        s.push_str(alias);
    }
    if entry.is_glob {
        s.push_str("::*");
    }
    s
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let mut violations: BTreeMap<String, Vec<String>> = BTreeMap::new();

    for src_dir in &dirs {
        for entry in WalkDir::new(src_dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) || is_prelude_path(path) {
                continue;
            }

            let module_path = match module_path_from(src_dir, path) {
                Some(mp) => mp,
                None => continue,
            };

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;

            if has_allow_tag(&src) {
                continue;
            }

            let syntax = syn::parse_file(&src)
                .with_context(|| format!("failed to parse {}", path.display()))?;

            let module_string = module_path_to_string(&module_path);

            for item in &syntax.items {
                if let Item::Use(item_use) = item {
                    if !matches!(item_use.vis, Visibility::Public(_)) {
                        continue;
                    }

                    let mut entries = Vec::new();
                    gather_use_tree(&item_use.tree, &mut Vec::new(), &mut entries);

                    for entry in entries {
                        if entry.is_glob {
                            continue;
                        }

                        let Some(abs_path) = resolve_absolute_path(&module_path, &entry.path) else {
                            continue;
                        };
                        if abs_path.is_empty() {
                            continue;
                        }

                        if abs_path.len() <= 1 {
                            continue;
                        }

                        let target_module = &abs_path[..abs_path.len() - 1];

                        let allowed = module_path.is_empty()
                            || target_module == module_path
                            || (target_module.len() > module_path.len()
                                && target_module[..module_path.len()] == module_path[..]);

                        if !allowed {
                            let target_string = module_path_to_string(target_module);
                            let use_repr = format_use_entry(&entry);
                            let mut message = format!(
                                "violating re-export `{}`: {} re-exports `{}` which is outside its subtree",
                                use_repr, module_string, target_string
                            );
                            message.push('\n');
                            message.push_str(&format!(
                                "    > Suggested fix: move the re-export into `{}` (or expose it via the descendant's api module).",
                                target_string
                            ));
                            message.push('\n');
                            message.push_str("    > If this cross-module re-export is intentional, document it and seek approval before adding `// allow:cross-reexport`.");

                            violations
                                .entry(path.display().to_string())
                                .or_default()
                                .push(message);
                        }
                    }
                }
            }
        }
    }

    if violations.is_empty() {
        println!("[OK] re-export hierarchy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        const MAX_FILES: usize = 20;
        const MAX_WARNINGS_PER_FILE: usize = 5;

        eprintln!("re-export hierarchy violations:");
        for (idx, (file, messages)) in violations.iter().enumerate() {
            if idx >= MAX_FILES {
                let remaining = violations.len().saturating_sub(MAX_FILES);
                if remaining > 0 {
                    eprintln!("  ... {} more file(s) with violations (output truncated)", remaining);
                }
                break;
            }

            eprintln!("  file: {} ({} violation(s))", file, messages.len());
            for (i, message) in messages.iter().enumerate() {
                if i >= MAX_WARNINGS_PER_FILE {
                    let remaining = messages.len().saturating_sub(MAX_WARNINGS_PER_FILE);
                    if remaining > 0 {
                        eprintln!("    ... {} additional violation(s) in this file", remaining);
                    }
                    break;
                }
                eprintln!("    - {message}");
            }
        }
        Err(anyhow!("violations found"))
    }
}
'''
[tasks.coverage-grcov]
description = "Generate code coverage report using grcov"
workspace = false
category = "Test"
script = '''
#!/usr/bin/env bash
./coverage.sh
'''

[tasks.coverage]
description = "Generate code coverage report"
workspace = false
category = "Test"
run_task = { name = "coverage-grcov" }

[tasks.lifetime-regression]
description = "Run lifetime regression suite (tests + coverage)"
workspace = false
category = "Test"
dependencies = ["coverage"]
