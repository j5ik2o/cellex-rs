[tasks.fmt]
description = "Format source code"
workspace = false
install_script = ['''
#!/usr/bin/env bash
rustup which rustfmt --toolchain nightly
if [ $? -ne 0 ]; then
  rustup install nightly
fi
''']
script = '''
#!/usr/bin/env bash
cargo +nightly fmt
'''

[tasks.sort-dependencies]
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! toml_edit = "0.22.0"
//! ```
use std::fs;
use std::path::Path;
use toml_edit::{Document, Item, Table, InlineTable};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cargo_toml_paths = [
        "Cargo.toml",
        "modules/utils-core/Cargo.toml",
        "modules/utils-std/Cargo.toml",
        "modules/message-derive-core/Cargo.toml",
        "modules/message-derive-std/Cargo.toml",
        "modules/actor-core/Cargo.toml",
        "modules/actor-std/Cargo.toml",
        "modules/remote-core/Cargo.toml",
        "modules/remote-std/Cargo.toml",
        "modules/cluster-core/Cargo.toml",
        "modules/cluster-std/Cargo.toml",
    ];

    for path in cargo_toml_paths.iter() {
        let path = Path::new(path);
        if path.exists() {
            backup_cargo_toml(path)?;
            sort_dependencies(path)?;
        } else {
            println!("Warning: {} not found", path.display());
        }
    }

    Ok(())
}

// Create a backup of Cargo.toml -> Cargo.toml.bak
fn backup_cargo_toml(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let backup_path = file_path.with_extension("toml.bak");
    fs::copy(file_path, &backup_path)?;
    println!("Backup created: {}", backup_path.display());
    Ok(())
}

fn sort_table(table: &mut Table) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_inline_table(table: &mut InlineTable) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_dependencies(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let content = fs::read_to_string(file_path)?;
    let mut doc = content.parse::<Document>()?;

    // Sort workspace dependencies
    if let Some(workspace) = doc.get_mut("workspace") {
        if let Some(deps) = workspace.get_mut("dependencies") {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted workspace.dependencies in {}", file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted workspace.dependencies in {}", file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    // Sort other dependency sections
    let sections = ["dependencies", "dev-dependencies", "build-dependencies"];

    for section in sections.iter() {
        if let Some(deps) = doc.get_mut(section) {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted {} in {}", section, file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted {} in {}", section, file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    fs::write(file_path, doc.to_string())?;
    println!("Updated {} successfully", file_path.display());

    Ok(())
}
'''

[tasks.check-source-policy]
description = "Enforce source policy: ban mod.rs and one top-level type/trait per file (workspace-aware, ignores tests.rs/lib.rs/main.rs)"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! regex = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use regex::Regex;
use std::{collections::HashSet, env, fs, path::{Path, PathBuf}};
use toml::Value;
use walkdir::WalkDir;

#[derive(Clone)]
struct TypeInfo {
    kind: &'static str,
    name: String,
}

struct TypeCollection {
    items: Vec<TypeInfo>,
    has_alias_or_union: bool,
}

struct MultiTypeViolation {
    path: PathBuf,
    items: Vec<TypeInfo>,
    has_alias_or_union: bool,
}

const RESERVED_FILE_BASENAMES: &[&str] = &["core", "common"];

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("ONE_TYPE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_comment(src: &str) -> bool {
    src.lines().take(80).any(|l| l.contains("allow:multi-types"))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn collect_top_level_types(src: &str) -> Result<TypeCollection> {
    let file = syn::parse_file(src)?;
    use syn::Item::*;
    let mut items: Vec<TypeInfo> = Vec::new();
    let mut has_alias_or_union = false;
    let mut seen: HashSet<String> = HashSet::new();
    for item in file.items {
        match item {
            Struct(data) => {
                let name = data.ident.to_string();
                let key = format!("struct:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "struct", name });
                }
            }
            Enum(data) => {
                let name = data.ident.to_string();
                let key = format!("enum:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "enum", name });
                }
            }
            Trait(data) => {
                let name = data.ident.to_string();
                let key = format!("trait:{name}");
                if seen.insert(key) {
                    items.push(TypeInfo { kind: "trait", name });
                }
            }
            Type(_) | Union(_) => has_alias_or_union = true,
            _ => {}
        }
    }
    Ok(TypeCollection { items, has_alias_or_union })
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let re_modrs = Regex::new(r"(^|/|\\)mod\\.rs$").unwrap();
    let mut errors: Vec<String> = Vec::new();
    let mut multi_type_violations: Vec<MultiTypeViolation> = Vec::new();

    for dir in &dirs {
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            if re_modrs.is_match(&path.to_string_lossy()) {
                errors.push(format!("mod.rs is not allowed: {}", path.display()));
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;
            if has_allow_comment(&src) {
                continue;
            }

            match collect_top_level_types(&src) {
                Ok(collection) => {
                    if collection.items.len() > 1 {
                        multi_type_violations.push(MultiTypeViolation {
                            path: path.to_path_buf(),
                            items: collection.items,
                            has_alias_or_union: collection.has_alias_or_union,
                        });
                    }
                }
                Err(e) => errors.push(format!("Parse error in {}: {e}", path.display())),
            }
        }
    }

    if errors.is_empty() && multi_type_violations.is_empty() {
        println!("[OK] source policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        eprintln!("source policy violations:");
        for e in &errors { eprintln!("  - {e}"); }
        for violation in &multi_type_violations {
            eprintln!(
                "  - {}: top-level items={}",
                violation.path.display(),
                violation.items.len()
            );
            for item in &violation.items {
                let suggestion = format_suggestion(&violation.path, item);
                eprintln!(
                    "    * {} {} -> {}",
                    item.kind,
                    item.name,
                    suggestion
                );
            }
            let dir = violation.path.parent().unwrap_or(Path::new("."));
            let core_path = dir.join("core.rs");
            if violation.path.file_name().and_then(|s| s.to_str()) == Some("core.rs") {
                eprintln!(
                    "    > After extraction: keep {} for module wiring only (`pub mod ...; pub use ...`).",
                    violation.path.display()
                );
            } else if core_path.exists() {
                eprintln!(
                    "    > After extraction: migrate module wiring from {} into existing {} (use `pub mod ...; pub use ...`).",
                    violation.path.display(),
                    core_path.display()
                );
            } else {
                eprintln!(
                    "    > After extraction: rename {} to {} and keep only module wiring (`pub mod ...; pub use ...`).",
                    violation.path.display(),
                    core_path.display()
                );
            }
            if violation.has_alias_or_union {
                let common_path = dir.join("common.rs");
                eprintln!(
                    "    > Remaining type aliases or unions? move them into {}.",
                    common_path.display()
                );
            }
        }
        Err(anyhow!("violations found"))
    }
}

fn format_suggestion(path: &Path, item: &TypeInfo) -> String {
    let dir = path.parent().unwrap_or(Path::new("."));
    let mut snake = to_snake_case(&item.name);
    if snake.is_empty() {
        snake = String::from("generated_type");
    }
    if RESERVED_FILE_BASENAMES.contains(&snake.as_str()) {
        snake.push_str("_type");
    }
    let file_name = format!("{}.rs", snake);
    let target = dir.join(&file_name);
    if target == path {
        format!("create {}", target.display())
    } else if target.exists() {
        format!("merge into existing {}", target.display())
    } else {
        format!("create {}", target.display())
    }
}

fn to_snake_case(name: &str) -> String {
    let mut result = String::new();
    let mut chars = name.chars().peekable();
    let mut prev_is_upper = false;
    let mut prev_is_underscore = false;
    while let Some(ch) = chars.next() {
        if ch.is_uppercase() {
            let next_is_lower = chars.peek().map(|c| c.is_lowercase()).unwrap_or(false);
            if !result.is_empty() && !prev_is_underscore && (!prev_is_upper || next_is_lower) {
                result.push('_');
            }
            for lower in ch.to_lowercase() {
                result.push(lower);
            }
            prev_is_upper = true;
            prev_is_underscore = false;
        } else if ch == '-' || ch == ' ' {
            if !result.ends_with('_') {
                result.push('_');
            }
            prev_is_upper = false;
            prev_is_underscore = true;
        } else {
            result.push(ch.to_ascii_lowercase());
            prev_is_upper = false;
            prev_is_underscore = ch == '_';
        }
    }
    result.trim_matches('_').to_string()
}
'''

[tasks.check-impl-co-location]
description = "Ensure struct definitions and inherent impl blocks live in the same file"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use std::collections::{HashMap, HashSet};
use std::{env, fs, path::{Path, PathBuf}};
use toml::Value;
use walkdir::WalkDir;

#[derive(Clone)]
struct FileEntry {
    path: PathBuf,
    allow_scatter: bool,
}

#[derive(Hash, Eq, PartialEq, Clone)]
struct TypeKey {
    crate_root: PathBuf,
    name: String,
}

#[derive(Default)]
struct TypeData {
    defs: Vec<FileEntry>,
    impls: Vec<FileEntry>,
}

const MULTI_DEF_ALLOWLIST: &[&str] = &["Inner"];

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("ONE_TYPE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_tag(src: &str, tag: &str) -> bool {
    src.lines().take(80).any(|l| l.contains(tag))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn dedup_entries(mut entries: Vec<FileEntry>) -> Vec<FileEntry> {
    entries.sort_by(|a, b| a.path.cmp(&b.path));
    entries.dedup_by(|a, b| a.path == b.path);
    entries
}

fn find_crate_root(dir: &Path) -> Option<PathBuf> {
    let mut current = dir;
    loop {
        if is_file_exists(&current.join("Cargo.toml")) {
            return Some(current.to_path_buf());
        }
        match current.parent() {
            Some(parent) => current = parent,
            None => return None,
        }
    }
}

fn collect_items(
    items: &[syn::Item],
    map: &mut HashMap<TypeKey, TypeData>,
    file_entry: &FileEntry,
    crate_root: &Path,
) {
    use syn::Item;
    for item in items {
        match item {
            Item::Struct(item_struct) => {
                let key = TypeKey {
                    crate_root: crate_root.to_path_buf(),
                    name: item_struct.ident.to_string(),
                };
                map.entry(key).or_default().defs.push(file_entry.clone());
            }
            Item::Impl(item_impl) => {
                if item_impl.trait_.is_none() {
                    if let Some(name) = extract_type_ident(&item_impl.self_ty) {
                        let key = TypeKey {
                            crate_root: crate_root.to_path_buf(),
                            name,
                        };
                        map.entry(key).or_default().impls.push(file_entry.clone());
                    }
                }
            }
            Item::Mod(item_mod) => {
                if let Some((_, nested)) = &item_mod.content {
                    collect_items(nested, map, file_entry, crate_root);
                }
            }
            _ => {}
        }
    }
}

fn extract_type_ident(ty: &syn::Type) -> Option<String> {
    match ty {
        syn::Type::Path(type_path) => {
            if type_path.qself.is_some() {
                return None;
            }
            type_path.path.segments.last().map(|seg| seg.ident.to_string())
        }
        _ => None,
    }
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let mut types: HashMap<TypeKey, TypeData> = HashMap::new();

    for dir in &dirs {
        let crate_root = find_crate_root(dir).unwrap_or_else(|| dir.clone());
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;
            let allow_scatter = has_allow_tag(&src, "allow:impl-scatter");

            let parsed = syn::parse_file(&src)
                .with_context(|| format!("failed to parse {}", path.display()))?;

            let file_entry = FileEntry {
                path: path.to_path_buf(),
                allow_scatter,
            };

            collect_items(&parsed.items, &mut types, &file_entry, &crate_root);
        }
    }

    let mut errors: Vec<String> = Vec::new();

    for (key, data) in types {
        let defs = dedup_entries(data.defs);
        let impls = dedup_entries(data.impls);

        if defs.is_empty() {
            continue; // likely external type
        }

        if defs.len() > 1 {
            if MULTI_DEF_ALLOWLIST.iter().any(|&name| name == key.name) {
                continue;
            }
            let locations = defs
                .iter()
                .map(|entry| entry.path.display().to_string())
                .collect::<Vec<_>>()
                .join(", ");
            errors.push(format!(
                "構造体 `{}` が複数のファイルで定義されています: {}",
                key.name,
                locations
            ));
            continue;
        }

        let def = &defs[0];
        if def.allow_scatter {
            continue;
        }

        for impl_entry in impls {
            if impl_entry.allow_scatter {
                continue;
            }

            if impl_entry.path != def.path {
                errors.push(format!(
                    "構造体 `{}` の定義({})とinherent impl({})が別ファイルにあります",
                    key.name,
                    def.path.display(),
                    impl_entry.path.display()
                ));
            }
        }
    }

    if errors.is_empty() {
        println!("[OK] impl co-location policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        eprintln!("impl co-location violations:");
        for err in &errors {
            eprintln!("  - {err}");
        }
        Err(anyhow!("violations found"))
    }
}
'''
[tasks.coverage-grcov]
description = "Generate code coverage report using grcov"
workspace = false
category = "Test"
script = '''
#!/usr/bin/env bash
./coverage.sh
'''

[tasks.coverage]
description = "Generate code coverage report"
workspace = false
category = "Test"
run_task = { name = "coverage-grcov" }

[tasks.lifetime-regression]
description = "Run lifetime regression suite (tests + coverage)"
workspace = false
category = "Test"
dependencies = ["coverage"]
