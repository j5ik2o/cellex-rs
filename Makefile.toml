[tasks.fmt]
description = "Format source code"
workspace = false
install_script = ['''
#!/usr/bin/env bash
rustup which rustfmt --toolchain nightly
if [ $? -ne 0 ]; then
  rustup install nightly
fi
''']
script = '''
#!/usr/bin/env bash
cargo +nightly fmt
'''

[tasks.sort-dependencies]
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! toml_edit = "0.22.0"
//! ```
use std::fs;
use std::path::Path;
use toml_edit::{Document, Item, Table, InlineTable};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cargo_toml_paths = [
        "Cargo.toml",
        "modules/utils-core/Cargo.toml",
        "modules/utils-std/Cargo.toml",
        "modules/message-derive-core/Cargo.toml",
        "modules/message-derive-std/Cargo.toml",
        "modules/actor-core/Cargo.toml",
        "modules/actor-std/Cargo.toml",
        "modules/remote-core/Cargo.toml",
        "modules/remote-std/Cargo.toml",
        "modules/cluster-core/Cargo.toml",
        "modules/cluster-std/Cargo.toml",
    ];

    for path in cargo_toml_paths.iter() {
        let path = Path::new(path);
        if path.exists() {
            backup_cargo_toml(path)?;
            sort_dependencies(path)?;
        } else {
            println!("Warning: {} not found", path.display());
        }
    }

    Ok(())
}

// Create a backup of Cargo.toml -> Cargo.toml.bak
fn backup_cargo_toml(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let backup_path = file_path.with_extension("toml.bak");
    fs::copy(file_path, &backup_path)?;
    println!("Backup created: {}", backup_path.display());
    Ok(())
}

fn sort_table(table: &mut Table) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_inline_table(table: &mut InlineTable) {
    let mut keys: Vec<_> = table.iter().map(|(k, _)| k.to_string()).collect();
    keys.sort();

    let sorted_table = keys.into_iter()
        .filter_map(|k| table.get(&k).map(|v| (k, v.clone())))
        .collect();

    *table = sorted_table;
}

fn sort_dependencies(file_path: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let content = fs::read_to_string(file_path)?;
    let mut doc = content.parse::<Document>()?;

    // Sort workspace dependencies
    if let Some(workspace) = doc.get_mut("workspace") {
        if let Some(deps) = workspace.get_mut("dependencies") {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted workspace.dependencies in {}", file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted workspace.dependencies in {}", file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    // Sort other dependency sections
    let sections = ["dependencies", "dev-dependencies", "build-dependencies"];

    for section in sections.iter() {
        if let Some(deps) = doc.get_mut(section) {
            match deps {
                Item::Table(table) => {
                    sort_table(table);
                    println!("Sorted {} in {}", section, file_path.display());
                },
                Item::Value(value) => {
                    if let Some(inline_table) = value.as_inline_table_mut() {
                        sort_inline_table(inline_table);
                        println!("Sorted {} in {}", section, file_path.display());
                    }
                },
                _ => {}
            }
        }
    }

    fs::write(file_path, doc.to_string())?;
    println!("Updated {} successfully", file_path.display());

    Ok(())
}
'''

[tasks.check-source-policy]
description = "Enforce source policy: ban mod.rs and one top-level type/trait per file (workspace-aware, ignores tests.rs/lib.rs/main.rs)"
workspace = false
script_runner = "@rust"
script = '''
//! ```cargo
//! [dependencies]
//! walkdir = "2"
//! glob = "0.3"
//! anyhow = "1"
//! regex = "1"
//! syn = { version = "2", features = ["full", "parsing"] }
//! toml = "0.8"
//! ```
use anyhow::{anyhow, Context, Result};
use glob::glob;
use regex::Regex;
use std::{collections::HashSet, env, fs, path::{Path, PathBuf}};
use toml::Value;
use walkdir::WalkDir;

fn read_toml(path: &Path) -> Result<Value> {
    let s = fs::read_to_string(path)
        .with_context(|| format!("failed to read {}", path.display()))?;
    Ok(s.parse::<Value>()?)
}

fn is_dir_exists(p: &Path) -> bool { p.exists() && p.is_dir() }
fn is_file_exists(p: &Path) -> bool { p.exists() && p.is_file() }

fn collect_source_dirs(root: &Path) -> Result<Vec<PathBuf>> {
    let root_toml = root.join("Cargo.toml");
    let doc = read_toml(&root_toml)
        .with_context(|| "failed to parse top-level Cargo.toml")?;

    let include_tests = env::var("ONE_TYPE_INCLUDE_TESTS").ok().as_deref() == Some("1");

    let mut exclude_patterns: Vec<String> = Vec::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(ex) = ws.get("exclude") {
            if let Some(arr) = ex.as_array() {
                for v in arr.iter().filter_map(|v| v.as_str()) {
                    exclude_patterns.push(v.to_string());
                }
            }
        }
    }

    let excluded = |p: &Path| -> bool {
        let s = p.to_string_lossy().to_string();
        exclude_patterns.iter().any(|pat| s.contains(pat))
    };

    let mut crate_dirs: HashSet<PathBuf> = HashSet::new();
    if let Some(ws) = doc.get("workspace") {
        if let Some(members) = ws.get("members") {
            if let Some(arr) = members.as_array() {
                for pat in arr.iter().filter_map(|v| v.as_str()) {
                    let pattern = root.join(pat).to_string_lossy().to_string();
                    for entry in glob(&pattern)? {
                        let path = entry?;
                        let dir = if path.is_file() { path.parent().unwrap().to_path_buf() } else { path.clone() };
                        if excluded(&dir) { continue; }
                        if is_file_exists(&dir.join("Cargo.toml")) {
                            crate_dirs.insert(dir);
                        }
                    }
                }
            }
        }
    }

    if doc.get("package").is_some() && !excluded(root) {
        crate_dirs.insert(root.to_path_buf());
    }

    let mut dirs: Vec<PathBuf> = Vec::new();
    for cd in crate_dirs {
        let src = cd.join("src");
        if is_dir_exists(&src) { dirs.push(src); }
        if include_tests {
            for extra in ["tests", "benches", "examples"] {
                let p = cd.join(extra);
                if is_dir_exists(&p) { dirs.push(p); }
            }
        }
    }

    dirs.sort();
    dirs.dedup();
    Ok(dirs)
}

fn has_allow_comment(src: &str) -> bool {
    src.lines().take(80).any(|l| l.contains("allow:multi-types"))
}

fn is_exception_file(path: &Path) -> bool {
    matches!(
        path.file_name().and_then(|s| s.to_str()),
        Some("lib.rs") | Some("main.rs") | Some("build.rs") | Some("tests.rs") | Some("core.rs") | Some("common.rs")
    )
}

fn count_top_level_types(src: &str) -> Result<usize> {
    let file = syn::parse_file(src)?;
    use syn::Item::*;
    let mut count = 0usize;
    for item in file.items {
        match item {
            Struct(_) | Enum(_) | Trait(_) => count += 1,
            _ => {}
        }
    }
    Ok(count)
}

fn main() -> Result<()> {
    let root = PathBuf::from(".");
    let dirs = collect_source_dirs(&root)?;
    if dirs.is_empty() {
        println!("[WARN] no source dirs detected from workspace; nothing to check");
        return Ok(());
    }

    let re_modrs = Regex::new(r"(^|/|\\)mod\\.rs$").unwrap();
    let mut errors: Vec<String> = Vec::new();

    for dir in &dirs {
        for entry in WalkDir::new(dir).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() { continue; }
            let path = entry.path();

            if path.extension().and_then(|e| e.to_str()) != Some("rs") {
                continue;
            }

            if is_exception_file(path) {
                continue;
            }

            if re_modrs.is_match(&path.to_string_lossy()) {
                errors.push(format!("mod.rs is not allowed: {}", path.display()));
                continue;
            }

            let src = fs::read_to_string(path)
                .with_context(|| format!("failed to read {}", path.display()))?;
            if has_allow_comment(&src) {
                continue;
            }

            match count_top_level_types(&src) {
                Ok(n) if n <= 1 => {}
                Ok(n) => errors.push(format!(
                    "More than one top-level type/trait in {} (found: {})",
                    path.display(), n
                )),
                Err(e) => errors.push(format!("Parse error in {}: {e}", path.display())),
            }
        }
    }

    if errors.is_empty() {
        println!("[OK] source policy passed on {} dirs:", dirs.len());
        for d in dirs { println!("  - {}", d.display()); }
        Ok(())
    } else {
        eprintln!("source policy violations:");
        for e in &errors { eprintln!("  - {e}"); }
        Err(anyhow!("violations found"))
    }
}
'''
[tasks.coverage-grcov]
description = "Generate code coverage report using grcov"
workspace = false
category = "Test"
script = '''
#!/usr/bin/env bash
./coverage.sh
'''

[tasks.coverage]
description = "Generate code coverage report"
workspace = false
category = "Test"
run_task = { name = "coverage-grcov" }

[tasks.lifetime-regression]
description = "Run lifetime regression suite (tests + coverage)"
workspace = false
category = "Test"
dependencies = ["coverage"]
